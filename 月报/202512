学城翻译能力优化
① 本月完成了系统性的翻译能力评测与用户反馈收集，确定了下一阶段模型能力优化方向。目前判断优化点主要包括：HTML格式遵循（或其他迭代版本的格式遵循能力）；漏译与语言混杂（需分析工程原因和模型原因）；语言生硬与黑话、专业术语翻译。通过收集通用翻译任务语料、美团内部Wiki与翻译日志、“大厂黑话”数据集，构建了多样化的评测基准。引用了XComet、GEMBA系列自动打分模型对翻译结果实现自动评价，在多源数据上验证了评分一致性（除了大厂黑话翻译打分不一致）。此外，搭建了自动化评测执行的工具，对多种来源和尺寸的模型完成了系统性评测，发现总体的翻译能力强依赖模型尺寸，longcat-18B系列相对较弱，longcat-flash与业界强模型处在同一范围。https://km.sankuai.com/collabpage/2734516560
；https://km.sankuai.com/collabpage/2732064030
② 12月计划一方面根据工程约束和产品需求给出模型选型参考与优化优先级，一方面基于已经收集的多样化数据和线上日志开展模型后训练，预期在上述优化方向取得初步成果。

学城新主页Agent架构升级
① 本月与产研侧完成了本方向的总体方案制定，共识了基于规划智能体与记忆模块、多种功能相关智能体协作的实现框架。目标在12月完成MVP上线，在春节前周期性实现功能更新。产品预期主要包含一个基于搜索入口，支持复杂Query，能够自主实现多种文档智能的办公AI。算法侧之前已经完成基于Deep Research框架的智能体搭建和Demo，12月核心是通过回收灰度用户的真实Query，分析执行效果与能力水位，对比不同方案设计并定位关键优化点。https://km.sankuai.com/collabpage/2734623907






数据构建： 30万左右的训练数据（专业术语翻译 + 中英葡互译通用语料）。
模型实验： 完成 LongCat 及 Qwen 系列共 5个模型 的SFT微调，并扩展“加权调和平均”的综合指标体系

实验主要结论和发现
1. 整体效果呈现“补短板、稳长板”的良性规律：
在多个LLM上进行SFT实验后，各模型的专业术语准确率（Acc@T）均获得大幅跃升；其他通用能力指标轻微波动，且“加权调和平均”的综合指标整体上扬。这证明了SFT策略在有效注入领域知识的同时，较好地兼顾了模型的通用性能。
2. 通用翻译能力呈现“低分显著提升、高分保持或微降”的现象：
若模型原本基础较弱（低分项），SFT后会有提升；若模型原本能力已较强（高分项），SFT后则呈现保持或轻微回落的现象。这表明当前SFT数据质量介于这些模型能力的平均水平，尚未达到显著超越强模型原生能力的“增强”水平，数据质量有待进一步提升。

后续计划
数据筛选（关键）： 针对“高分微降”现象，引入 Qwen3-30B-A3B 模型对数据进行精细化筛选，确保监督信号质量超越模型均值。
RLHF迭代： 在SFT模型基础上，进行强化学习训练，进一步提升性能。






整体业务进展
1. 翻译模型能力优化：针对术语知识内化、漏译（原文译文混杂）、HTML结构保持，基于5个基础模型（Qwen3-8B, Qwen25-7B-Instruct, LongCat-Flash-Chat, LongCat-8B-Chat-0523, LongCat-sales-18B-Chat）在近300w数据上，完成了两轮翻译优化方法论（SFT + RLHF）验证性试验，确定选型Qwen3-8B，术语内化率上限可突破90%以上，漏译和HTML结构错误问题可显著改善（具体指标暂未统计）。正式版本训练中，预计1月中旬交付第一个可灰度版本。
2. 学城新主页Agent：本月进一步与产品开发细化了单Agent多轮任务规划+工具调用的具体框架，明确算法和产研侧分工及协作模式，算法主R Agent各环节效果有优化，包括首页联想推荐问、任务规划+工具调用、智能创作类AI能力支持等。联想推荐问预计1.20左右跟随第一个MVP版Agent一起上线，多轮任务规划+工具调用优化水位评测在联调之后开始，其他AI能力待定。

核心技术探索
1. SFT + RLHF -> 翻译优化
- 主要经验沉淀：1. 翻译不同于其他任务吗，数据量更大效果更好：仅在20w术语翻译数据集上训练，术语内化率60%左右，加入200w+的通用翻译数据，术语内化率可突破90%以上。2. 通用指令遵循能力以及HTML结构保持能力大幅丧失，可通过加入20%左右的通用指令数据+HTML翻译数据得以保留。3. 全量微调比Lora微调效果好，1个epoch最佳，2个epoch开始过拟合。
- 优化效果分析
整体效果呈现“补短板、稳长板”的良性规律：第一轮试验在多个LLM上进行SFT实验后，各模型专业术语准确率（Acc@T）均从30%左右提升至60%左右，其他自动化指标（XCOMET、GEMBA）轻微波动±5%以内；第二轮试验聚焦Qwen3-8B，扩充大量通用翻译数据，术语内化率提升至90%以上，其他自动化指标波动幅度进一步缩小±3%以内。术语准确率和通用翻译指标呈一定的负相关性。
通用翻译能力“低分显著提升、高分保持或微降”：若模型原通用指标较低（低分项），SFT后会有提升；若原通用指标已较高（高分项），SFT后则呈现保持或轻微回落的现象。提升数据质量，可缩小回落幅度，高质量数据集是翻译效果的瓶颈。
加入20%左右的通用指令数据+HTML翻译数据，可保留通用指令遵循能力以及HTML结构保持能力，是否会影响术语准确率和通用指标待验证。


2. 翻译评测指标一致性评估 & 高质量数据集构建
- 自动评测指标与人工评测一致性：Qwen3-8B翻译457条zh->pt数据，GEMBA-ESA指标上和人工一致性较好，AUC 0.81 (良好水平), Spearman ρ 0.64 (中偏强相关), p-value: 0.0 (高度显著)；XCOMET-XL和人工几乎无相关性（与WMT和XCOMET官方给的结论有显著差异，待进一步分析）。
- 高质量数据集构建：1. 人工从学城文档Markdown捞了将近9000条纯文本高质量片段，用gpt翻译成了英、葡、法、俄等多种语言，后续用于学城领域知识内化；2. 从学城翻译日志中捞出3500+原始html格式的模型输入输出，由学城一线业务同学人工校验；3. 实习生同学开始进行葡语互译数据人工标注。









整体业务进展
翻译模型能力优化

针对术语知识内化、漏译（原文与译文混杂）、HTML结构保持等核心问题，基于5个基础模型（Qwen3-8B、Qwen25-7B-Instruct、LongCat-Flash-Chat、LongCat-8B-Chat-0523、LongCat-sales-18B-Chat），在近300万条数据上完成了两轮翻译优化方法论（SFT + RLHF）的验证性试验。最终确定选型 Qwen3-8B：其术语内化率上限可突破90%以上，漏译及HTML结构错误问题亦可显著改善（具体量化指标暂未统计）。当前正式版本正在训练中，预计1月中旬交付首个可灰度发布的版本。
学城新主页 Agent

本月进一步与产品及开发团队细化了单 Agent 多轮任务规划与工具调用的具体框架，明确了算法与产研侧的分工及协作机制。算法侧主 R Agent 在多个环节的效果持续优化，包括首页联想推荐问、任务规划+工具调用、智能创作类 AI 能力支持等。其中，联想推荐问功能预计于1月20日左右随首个 MVP 版 Agent 一同上线；多轮任务规划与工具调用的优化水位评测将在联调完成后启动；其余 AI 能力上线计划待定。
核心技术探索
1. 基于 SFT + RLHF 的翻译能力优化
通过两轮系统性实验，围绕术语内化、通用翻译质量、指令遵循能力及 HTML 结构保持等维度，形成以下关键结论：

数据规模与术语内化效果强相关：仅使用20万条术语翻译数据进行训练时，术语内化率约为60%；当叠加200万+通用翻译数据后，术语内化率显著提升至90%以上，表明大规模高质量数据对专业术语内化具有决定性作用。
通用能力与专业能力存在权衡关系：全量微调（Full Fine-tuning）效果优于 LoRA 微调；1个 epoch 为最佳训练轮次，第2个 epoch 开始出现过拟合。值得注意的是，单纯聚焦术语优化会导致模型通用指令遵循能力与 HTML 结构保持能力大幅退化；但通过在训练集中引入约20%的通用指令数据与 HTML 翻译数据，可有效保留这两项关键能力——该策略对术语准确率及通用翻译指标的影响尚待进一步验证。
整体优化呈现“补短板、稳长板”的良性规律：
第一轮 SFT 实验在多个 LLM 上开展，各模型的专业术语准确率（Acc@T）普遍从约30%提升至60%左右，而其他自动化指标（如 XCOMET、GEMBA）波动控制在 ±5% 以内。
第二轮聚焦 Qwen3-8B，通过扩充大量通用翻译数据，术语内化率突破90%，同时通用指标波动进一步收窄至 ±3% 以内。
通用翻译能力变化呈现分层特征：对于原始通用翻译指标较低的模型（“低分项”），SFT 后显著提升；而对于原始指标已较高的模型（“高分项”），则表现为基本保持或轻微回落。进一步分析表明，提升训练数据质量是缩小高分项回落幅度的关键，高质量数据集已成为当前翻译效果提升的核心瓶颈。
2. 翻译评测指标一致性评估 & 高质量数据集构建
自动评测与人工评测一致性分析：

使用 Qwen3-8B 对457条中文→葡萄牙语样本进行翻译，结果显示 GEMBA-ESA 指标与人工评分具有良好一致性（AUC = 0.81，Spearman ρ = 0.64，p-value < 0.001），达到中偏强相关水平；而 XCOMET-XL 与人工评分几乎无相关性，此现象与 WMT 及 XCOMET 官方结论存在显著差异，需进一步深入分析。
高质量数据集构建进展：
从学城文档 Markdown 中人工筛选近9,000条纯文本高质量片段，并利用 GPT 翻译为英、葡、法、俄等多种语言，用于后续学城领域知识内化；
从学城翻译日志中提取3,500+条原始 HTML 格式的模型输入输出样本，由一线业务同学完成人工校验；
实习生已启动葡萄牙语双向翻译数据的人工标注工作。


